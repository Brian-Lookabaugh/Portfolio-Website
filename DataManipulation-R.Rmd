---
title: "Guide to Data Manipulation in R"
author: "Brian Lookabaugh"
output: html_document
---

My first experience with statistical programming began with a tool known as Stata. While this program is relatively popular in areas such as political science and economics, it is not widely used in most other contexts. However, I was always fond of Stata due to its incredibly simple syntax. If I wanted to keep a variable, I would simply `keep var`. If I wanted to drop a variable, I would `drop var`. It was really that simple. Coming form that background, transitioning from R was a bit intimidating at first. And because I remember how that transition went, I have created this document to detail basic, but crucial, data manipulation tasks in R for those currently in transition to R. In addition, I also plan to use this document *regularly* for those days when I'm unable to remember the exact syntax that I need.

First, we're going to load the required packages for this document:

```{r message=FALSE, results="hide"}
library(readxl) ## Importing Excel Documents
library(tidyverse) ## Easy Data Manipulation
```

As a quick side note, while this is not necessary in this example given that we are only loading two packages, in a true data science project, you will be loading numerous packages. Rather than typing `library(X)` for every individual package, you can use the following format, which does the same thing as the code above:

```{r, results="hide"}
pacman::p_load(
  "readxl",
  "tidyverse"
)
```

# Importing and Merging Data

Now, we are going to import data from an Excel spreadsheet into RStudio:

```{r}
VDEM_data <- read_excel("C:/Users/brian/Desktop/Dissertation & Projects/Data/VDEM Example Data.xlsx")
```

This snippet of the very large and comprehensive Varieties of Democracy (V-Dem) data set includes information on civil society strength, GDP per capita, oil and natural gas income, and regime types of over 100 countries ranging from the late 1700s to the present. However, say that I also want information on international trade in my final data set. This information was not included in my data set. Luckily, I do have access to this information in another Excel spreadsheet. However, if I want information from both of these data sets together, I will need to merge the two data sets. I can do this with the following code. First, we need to load the trade data itself:

```{r}
trade_data <- read_excel("C:/Users/brian/Desktop/Grad School/Data2/Data/Raw Spreadsheet Data/COW_Trade.xlsx")
```

Next, we'll need to actually *merge* these data sets. While you can do this with base R syntax, we are going to use the dplyr method, which uses SQL syntax to join data sets together. For the purposes of this example, we are going to be using an INNER JOIN function. What this means is that the final data set will only rows that matched for both data sets. If you find yourself in a situation where you need less restrictive criteria, you can explore LEFT JOINs, RIGHT JOINs and OUTER JOINs. OUTER JOINs are the exact opposite of INNER JOINs in that they include *all* information from *both* data sets, regardless of whether the two data sets had values that did not match. LEFT JOINs include all information from the left (or first specified) data set but only include information from the right (or second) data set that matches with the left data set. As you can infer, a RIGHT JOIN does the exact opposite. For out data to merge, we also need to specify the value that we are merging them by. Essentially, this is the value that we are telling R is common across both data sets. This be practically be anything from countries to US states to individuals, etc. For our purposes, we are going to use the "ccode" variable, a numeric code for countries, and the year variable to fulfill this role:

```{r}
merged_data <- inner_join(VDEM_data, trade_data,
               by = c("ccode", "year"))
```

So, what did we actually do here? For one, we now have a data set that has all of the information from both the VDEM and the Trade data sets together into one composite data set. However, by stipulating an INNER JOIN, this data set only includes observations with countries that were in *both* the VDEM and Trade data set. If we had specified an OUTER JOIN function, then we would have information on *all* countries from both data sets, regardless of whether they were included in only one of the data sets. If we had specified a LEFT JOIN, we would have information on all of the countries in the VDEM data set, regardless of whether these countries were present in the Trade data set. However, if we had unique countries in the Trade data set that were not present in the VDEM data set, these would have been dropped. You can reverse these last 2 sentences to figure out what a RIGHT JOIN would have given you. We have a merged data set now and that is great. However, is was really convenient that our cross-sectional ID variable that we were merging on happened to be named the exact same thing in both data sets. Oftentimes, this won't be true. How do we merge data sets if this is the case? To get started, let's rename this country code variable in one of the data sets:

```{r, results="hide"}
trade_data <- trade_data %>%
  rename(country_code = ccode)
```

Okay, now let's see how we would merge these data sets together with different names for the same value that we are going to merge on:

```{r}
merged_data <- inner_join(VDEM_data, trade_data,
               by = c("ccode" = "country_code", "year"))
```

There we go! Now we know how to merge data sets where the ID variable that is being merged on has different names.

# Keeping/Dropping Information

When acquiring a data set, we are often given additional data that is not necessarily needed. Below, syntax is provided for keeping/dropping columns (variables), keeping/dropping rows (observations) and dealing with duplicate values.

### Keeping/Dropping Columns

Keeping columns is useful when we do not need the majority of columns in our data set. In contrast, you may want to drop columns if you need most of the columns in the data set, but just need to select out a couple/few columns The first chunk of code is creating a new data set that is keeping only the country code, year, GDP per capita, and imports columns. The second chunk of code is deleting the alternative "country_id" and country name columns:

```{r}
keep_data <- merged_data %>%
  select(c(ccode, year, e_gdppc, imports))
```

```{r}
drop_data <- merged_data %>%
  select(-c(country_id, country))
```

This code works well for keeping/dropping columns. However, how would we do something similar for filtering rows? We can use the `filter` command to meet these goals. Below, we are creating a new data set that *only* includes wealthier (e_gdppc \>= 10) democracies (v2x_regime \> 1):

```{r}
rich_democs <- merged_data %>%
  filter(v2x_regime > 1 & e_gdppc >= 10)
```

We could also reverse this and create a data set of comparatively non-wealthy autocracies:

```{r}
poor_autocs <- merged_data %>%
  filter(v2x_regime < 2 & e_gdppc < 10)
```

We can also use an "or" condition. Perhaps we want a data set that includes democracies and/or countries with a large amount of petroleum production:

```{r}
democ_or_oil <- merged_data %>%
  filter(v2x_regime > 1 | e_total_resources_income_pc >= 350)
```

### Duplicate Values

Oftentimes, especially when merging data, we end up with duplicate values. For example, in a data set such as this, we might find that we have two unique rows for "Suriname 2007" or "Australia 1994". Duplicates are a common problem, but there is an easy way to deal with them. The following line of code tells you how many duplicates are present within your data set:

```{r}
sum(duplicated(merged_data))
```

It turns out that I do not have any duplicates in this data set. However, if I did, how would you go about dropping these duplicates? In the following line of code, I am going to remove rows where the country code-year pairing is the exact same across 2 or more rows:

```{r}
merged_data <- merged_data %>%
  distinct(ccode, year, .keep_all = TRUE)
```

# Renaming Data

Here, I am going to simply rename a column. Note that we have already documented this syntax earlier when we renamed "ccode" to "country_code" but we are going to go through another simple example where we rename two variables in a single line of code:

```{r}
merged_data <- merged_data %>%
  rename(regime_type = v2x_regime, gdp_pc = e_gdppc)
```

# Creating New Variables

In my opinion, creating new variables represents the "meat" of data manipulation. In my personal research, this is the part of the data manipulation process that I end up having the most lines of code dedicated to. Below, I will provide numerous lines of code to demonstrate how to create a variety of new variables.

### Creating a Dummy Variable

Here, we are going to create a dummy variable for whether a country is a democracy:

```{r}
merged_data <- merged_data %>%
  mutate(democracy = case_when(
    regime_type > 1 ~ 1,
    regime_type < 2 ~ 0
  ))
```

Alternatively, we can also use the `if_else` command to do the same thing:

```{r}
merged_data <- merged_data %>%
  mutate(democracy2 =
    if_else(regime_type > 1, 1, 0))
```

In fact, the `if_else` command is useful for all sorts of "True or False" statements that we may want to apply to a newly generated variable. For example, maybe we would like a dummy variable that takes a value of "1" if a country has the highest civil society score in a given year. We can do this with the following code:

```{r}
merged_data <- merged_data %>%
  group_by(year) %>%
  mutate(biggest_CSO = 
    if_else(v2xcs_ccsi == max(v2xcs_ccsi), 1, 0))
```

Alternatively, if we modify the `group_by` command to grouping by country instead of year, we can get a variable that let's us know the year(s) with the highest civil society score for each individual country:

```{r}
merged_data <- merged_data %>%
  group_by(ccode) %>%
  mutate(biggest_CSO2 = 
    if_else(v2xcs_ccsi == max(v2xcs_ccsi), 1, 0))
```

### Creating an Ordinal Variable

Here, we are going to create an ordinal, three-unit (0-2) variable for civil society strength:

```{r}
merged_data <- merged_data %>%
  mutate(ordered_CSO = case_when(
    v2xcs_ccsi < .33 ~ 0,
    v2xcs_ccsi >= .33 & v2xcs_ccsi < .66 ~ 1,
    v2xcs_ccsi >= .66 ~ 2
  ))
```

### Creating a Categorical Variable

Now, we are going to create categorical variables that serve as a numeric value to reflect a country's region. However, these numbers are not ordinal (a value of "2" (South America) is not greater than a value of "1" (North America) since this makes no sense). So, we will need to convert this variable to a factor variable so that R does not treat them as such and instead, recognizes that these numbers are simply symbols of which region a country belongs to.

```{r}
merged_data <- merged_data %>%
  mutate(region = factor(case_when(
    ccode < 100 ~ 1, ## North America 
    ccode >= 100 & ccode < 200 ~ 2, ## South America
    ccode >= 200 & ccode < 400 ~ 3, ## Europe
    ccode >= 400 & ccode < 600 ~ 4, ## Sub-Saharan Africa
    ccode >= 600 & ccode < 700 ~ 5, ## Middle East and North Africa
    ccode >= 700 & ccode < 900 ~ 6, ## Asia
    ccode >= 900 ~ 7 ## Oceania
  )))
```

### Creating a Log-Transformed Variable

Oftentimes, the distribution of a variable is highly right-skewed, clearly departing from a normal distribution that we naturally assume most of our variables have. In the social sciences, the most infamous right-skewed variable is GDP per capita. Typical treatment of this variable includes a log-transformation of the variable so that it can be appropriately used in statistical models. Still, GDP per capita is not the *only* variable that is treated this way. Because of this, it is good to know how to log-transform a variable in R. I am also going to add +1 to each value prior to the log-transformation. While this variable in particular does not need this, I have personally come across many right-skewed variables that had values of 0. Adding +1 to the column is not perfect, however, it does make a log-transformation of initially "0" values nonsensical since a log-transformation of "1" is simply "0". The consequences of not treating your "0" observations while instituting a log-transformation manifest as post-log-transformation values that do not make any sense:

```{r}
merged_data <- merged_data %>%
  mutate(
    lGDPpc = log(gdp_pc + 1)
  )
```

### Creating a Lagged and Lead Variable

In some cases, when preparing our data for statistical modeling, we may have theoretical reasons to believe that the relationship between our dependent variable and independent variable(s) is not instantaneous. In some cases, we may expect that our dependent variable in the present can be explained by things that happened in the past (this is a lagged effect). In other words, we also might say that the effect of our independent variables will not be present until sometime in the future. For example, we might have a reason to believe that the effect of a new community healthcare program will take time to impact community health. This would be an example of a lagged effect. We also might have reasons to believe that our dependent variable in the future is reactive to our independent variables in the present (lead effect). For example, if we are trying to explain what motivates U.S. foreign aid, we have to understand that U.S. foreign aid allocation is reactive to events that have happened in the past. Below, code is presented that demonstrates how one can generate a lagged and lead variable by one time period. If one wishes to modify the size of the lagged/lead effect, one simply changes `n = 1` to `n = 3`, `n = 5`, etc. Note that we are grouping by country so that the lagged and lead effects are generated *within* countries. Otherwise, countries may be accidentally receiving the lagged/lead values of *other* countries:

```{r}
merged_data <- merged_data %>%
  group_by(ccode) %>%
  mutate(
    lag_democ = lag(democracy, n = 1, order_by = ccode)
  )
```

```{r}
merged_data <- merged_data %>%
  group_by(ccode) %>%
  mutate(
    lead_democ = lead(democracy, n = 1, order_by = ccode)
  )
```

### Creating a Count Variable

Depending on what our project is, we may want a variable that serves as a count of some sort. For example, maybe I would like a count of the years that a country has been in this data set. To do this, I can execute the following:

```{r}
merged_data <- merged_data %>%
  group_by(ccode) %>%
  mutate(year_count = row_number())
```

Alternatively, I may want this variable to simply serve as a summary as the total years a country spent in my data set:

```{r}
merged_data <- merged_data %>%
  group_by(ccode) %>%
  mutate(total_years = max(year_count))
```

# Sorting Data

An important aspect of data management is keeping a data set clean and orderly. The following code below will demonstrate how to arrange columns and rows in pursuit of this data management ideal.

### Arranging Columns

Here, we are re-arranging the columns in the data set so that the "country" variable shows up first at the far-left-hand side, "ccode" is after that, "year" is after that, etc. However, after exports, we are specifying `everything())` so that we are not dropping columns that we did not have a specified order for.

```{r}
merged_data <- merged_data %>%
  select(country, ccode, year, democracy, imports, exports, everything())
```

### Arranging Rows

Here, I am specifying that I would like for my data to be sorted by country and by year. Because I am using "ccode" as my country identifier and due to the fact that, unless specified otherwise, `arrange` will sort in ascending order, the first observations listed in this newly formatted data set are the United States (with the smallest ccode of "2") in the late 1800s (the earliest years that the US is recorded in this data set)

```{r}
merged_data <- merged_data %>%
  arrange(ccode, year)
```

However, if we would like to sort this in descending order for countries instead, we can do so simply by:

```{r}
merged_data <- merged_data %>%
  arrange(desc(ccode), year)
```


